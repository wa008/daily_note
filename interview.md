2021-04-11

1. 过滤模型的提升原因
2. n-grams 和 whold word mask混用，一个word两个token会被算作是一个token，mask token占比15%
3. albert相比原生bert做了哪些优化
4. cbow和glove的区别
   1. cbow是用上下文单词预测当前单词，基于词向量；cbow使用输入还是输出embeding
   2. glove利用共显count来预测，基于count-base
5. self-attention 的复杂度：n^2*d
6. KS曲线介绍
7. 拓展题
   1. 新词生成，题目没太懂
      1. 信息熵：取上下文熵最小的词；
      2. 词的内部凝聚性高

