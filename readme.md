## DO LIST

### doing
1. 日常
   1. 早上：李宏毅的课
   2. 日常：deep learning - the batch+博客
   3. 晚上：kaggle
2. kaggle
   1. 预测：[Answer Correctness Prediction](https://www.kaggle.com/c/riiid-test-answer-prediction/overview)
      1. 跑了个transformer in pytorch 的demo，其整体结构就是输入一个向量，输出一个向量
   2. Real or Not? NLP with Disaster Tweets，ongoing，已经有人score=1
3. 李宏毅的课
4. Attention+transformer+bert
   1. 论文：[Attention Is All You Need](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf)，2 Background
   2. 李宏毅课件+youtube讲解
   3. 博客：[Attention? Attention! - Lil'Log](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)
   4. [美团博客实践](https://tech.meituan.com/2020/04/16/transformer-in-meituan.html)
5. 《深度学习》，系统地学一遍
   1. RNN反向传播怎么处理多轮的梯度：看《深度学习》中RNN的反向传播
6. [语言模型和视觉的融合才是未来？](https://blog.deeplearning.ai/blog/the-batch-new-year-wishes-from-fei-fei-li-harry-shum-ayanna-howard-ilya-sutskever-matthew-mattina?_gl=1*lg4056*_ga*MTQ2Njg4ODMxMi4xNTk3OTc1NDQy*_ga_FNZ5N2KPET*MTYxMDA4MTk2Ni4yLjAuMTYxMDA4MTk2Ni4w)
### todo
1. Kaggle，Cornell Birdcall Identification，2020.9.8
2. [学生答题正确性预测](https://www.biendata.xyz/competition/chaindream_mooccube_task2/)，2020.11.15
3. [腾讯的黑灰产对抗实战](https://mp.weixin.qq.com/s/JO4xbmGenjZnt_1tJBO4jA)
4. confidence_ellipse： 绘制二位数据集的置信椭圆
5. lime: 模型解释工具
6. XGBoost相关
   1. lightGMB
   2. catboost
7. course
   1. coursera: 其他类型的课程，比如Google认证证书

### done
1. kaggle
   1. NLP入门，Kaggle比赛，Spooky Author Identification，验证集准确率71%
2. coursera
   1. [deep learning](https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome)
   2. nlp from deeplearning.ai
3. 机器学习
   1. GBDT
   2. XGBoost
   3. [How You Should Read Research Papers According To Andrew Ng (Stanford Deep Learning Lectures)](https://towardsdatascience.com/how-you-should-read-research-papers-according-to-andrew-ng-stanford-deep-learning-lectures-98ecbd3ccfb3)
4. 深度学习
   1. lstm最后一层隐藏层和输出层的区别：lstm只有隐藏层和记忆细胞，没有输出层，因此使用隐藏层作为下一线性层的输入是正确的。
   2. GRU、LSTM，是在RNN基础上添加不同的门控单元，比如添加长期记忆，长期记忆消除因子。那么不同的场景添加符合业务的门控单元，或许也能学习到相应的内容。
5. 其他
   1. github：[how-to-get-rich-without-getting-lucky](https://github.com/fat-garage/how-to-get-rich-without-getting-lucky)
   2. 浪潮之巅上册，6 / 17

